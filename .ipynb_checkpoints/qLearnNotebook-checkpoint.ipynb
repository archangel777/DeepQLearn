{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ErickLima\\Anaconda2\\lib\\site-packages\\skimage\\viewer\\utils\\core.py:10: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  warn(\"Recommended matplotlib backend is `Agg` for full \"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named pygame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b59525aa81b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"games/Fake-Arkanoid/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;31m#import wrapped_flappy_bird as game_flappy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mwrapped_arkanoid\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgame_arkanoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ErickLima\\Desktop\\UFC\\2017.1\\Reinforcement Learning\\DeepQ\\games\\Fake-Arkanoid\\wrapped_arkanoid.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mmain_arkanoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mGameState\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_arkanoid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ErickLima\\Desktop\\UFC\\2017.1\\Reinforcement Learning\\DeepQ\\games\\Fake-Arkanoid\\main_arkanoid.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mpygame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpygame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pygame"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import skimage as skimage\n",
    "from skimage import transform, color, exposure\n",
    "from skimage.transform import rotate\n",
    "from skimage.viewer import ImageViewer\n",
    "import sys, os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "sys.path.append(\"games/flappy/\")\n",
    "sys.path.append(\"games/Fake-Arkanoid/\")\n",
    "#import wrapped_flappy_bird as game_flappy\n",
    "import wrapped_arkanoid as game_arkanoid\n",
    "import random\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from collections import deque\n",
    "import matplotlib.cm as cm\n",
    "import pylab as pl\n",
    "\n",
    "import json\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.initializers import normal, identity\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD , Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GAME = 'bird' # the name of the game being played for log files\n",
    "CONFIG = 'nothreshold'\n",
    "ACTIONS = 3 # number of valid actions\n",
    "GAMMA = 0.99 # decay rate of past observations\n",
    "OBSERVATION = 100. # timesteps to observe before training\n",
    "EXPLORE = 2000. # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.01 # final value of epsilon\n",
    "INITIAL_EPSILON = 1 # starting value of epsilon\n",
    "EPSILON_DECAY = (INITIAL_EPSILON - FINAL_EPSILON)/EXPLORE\n",
    "REPLAY_MEMORY = 1000000 # number of previous transitions to remember\n",
    "BATCH = 32 # size of minibatch\n",
    "FRAME_PER_ACTION = 5\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "img_rows , img_cols = 80, 80\n",
    "#Convert image into Black and white\n",
    "img_channels = 4 #We stack 4 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyModel:\n",
    "    def __init__(self):\n",
    "        print(\"Now we build the model\")\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(32, (4, 4), strides=(2, 2), padding=\"same\", input_shape=(img_rows,img_cols,img_channels)))  #80*80*4\n",
    "        self.convout1 = Activation('relu')\n",
    "        self.model.add(self.convout1)\n",
    "        self.model.add(Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\"))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\"))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(512))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dense(ACTIONS))\n",
    "       \n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        self.model.compile(loss='mse',optimizer=adam)\n",
    "        print(\"We finish building the model\")\n",
    "\n",
    "    def make_mosaic(self, imgs, nrows, ncols, border=1):\n",
    "        \"\"\"\n",
    "        Given a set of images with all the same shape, makes a\n",
    "        mosaic with nrows and ncols\n",
    "        \"\"\"\n",
    "        nimgs = imgs.shape[0]\n",
    "        imshape = imgs.shape[1:]\n",
    "        print(imshape)\n",
    "        \n",
    "        mosaic = ma.masked_all((nrows * imshape[0] + (nrows - 1) * border,\n",
    "                                ncols * imshape[1] + (ncols - 1) * border),\n",
    "                                dtype=np.float32)\n",
    "        \n",
    "        paddedh = imshape[0] + border\n",
    "        paddedw = imshape[1] + border\n",
    "        for i in range(nimgs):\n",
    "            row = int(np.floor(i / ncols))\n",
    "            col = i % ncols\n",
    "            \n",
    "            mosaic[row * paddedh:row * paddedh + imshape[0],\n",
    "                   col * paddedw:col * paddedw + imshape[1]] = imgs[i]\n",
    "        return mosaic\n",
    "\n",
    "    def nice_imshow(self, ax, data, vmin=None, vmax=None, cmap=None):\n",
    "        \"\"\"Wrapper around pl.imshow\"\"\"\n",
    "        if cmap is None:\n",
    "            cmap = cm.jet\n",
    "        if vmin is None:\n",
    "            vmin = data.min()\n",
    "        if vmax is None:\n",
    "            vmax = data.max()\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        im = ax.imshow(data, vmin=vmin, vmax=vmax, interpolation='nearest', cmap=cmap)\n",
    "        pl.colorbar(im, cax=cax)\n",
    "\n",
    "    def trainNetwork(self, args):\n",
    "        # open up a game state to communicate with emulator\n",
    "        #game_state = game_flappy.GameState()\n",
    "        game_state = game_arkanoid.GameState(True)# if args['mode'] == 'Run' else False)\n",
    "\n",
    "        # store the previous observations in replay memory\n",
    "        D = deque()\n",
    "\n",
    "        # get the first state by doing nothing and preprocess the image to 80x80x4\n",
    "        do_nothing = np.zeros(ACTIONS)\n",
    "        do_nothing[0] = 1\n",
    "        x_t, r_0, terminal = game_state.frame_step(do_nothing)\n",
    "\n",
    "        x_t = skimage.color.rgb2gray(x_t)\n",
    "        x_t = skimage.transform.resize(x_t,(img_rows,img_cols), mode='constant')\n",
    "        #x_t = skimage.exposure.rescale_intensity(x_t,out_range=(0,255))\n",
    "\n",
    "        #viewer = ImageViewer(x_t)\n",
    "        #viewer.show()\n",
    "\n",
    "        s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "        #print (s_t.shape)\n",
    "\n",
    "        #In Keras, need to reshape\n",
    "        s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])  #1*80*80*4\n",
    "\n",
    "        if os.path.isfile(\"model.h5\"):\n",
    "            print (\"Now we load weight\")\n",
    "            self.model.load_weights(\"model.h5\")\n",
    "            adam = Adam(lr=LEARNING_RATE)\n",
    "            self.model.compile(loss='mse',optimizer=adam)\n",
    "            print (\"Weight load successfully\")\n",
    "\n",
    "        if args['mode'] == 'Run':\n",
    "            OBSERVE = 999999999    #We keep observe, never train\n",
    "            epsilon = FINAL_EPSILON    \n",
    "        else:                       #We go to training mode\n",
    "            OBSERVE = OBSERVATION\n",
    "            epsilon = INITIAL_EPSILON\n",
    "\n",
    "        t = 0\n",
    "        loss = 0\n",
    "        prev_points = 0\n",
    "        while (True):\n",
    "            Q_sa = self.model.predict(s_t)       #input a stack of 4 images, get the prediction\n",
    "            action_index = 0\n",
    "            r_t = 0\n",
    "            a_t = np.zeros([ACTIONS])\n",
    "            #choose an action epsilon greedy\n",
    "            if random.random() <= epsilon:\n",
    "                #print(\"----------Random Action----------\")\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                a_t[action_index] = 1\n",
    "            else:\n",
    "                max_Q = np.argmax(Q_sa)\n",
    "                action_index = max_Q\n",
    "                a_t[max_Q] = 1\n",
    "\n",
    "            #We reduced the epsilon gradually\n",
    "            if epsilon > FINAL_EPSILON + EPSILON_DECAY and t > OBSERVE:\n",
    "                epsilon -= EPSILON_DECAY\n",
    "\n",
    "            #run the selected action and observed next state and reward\n",
    "            terminal = False\n",
    "            for _ in range(FRAME_PER_ACTION-1):\n",
    "                _, _, terminal_aux = game_state.frame_step(a_t)\n",
    "                terminal = terminal_aux or terminal\n",
    "\n",
    "            x_t1_colored, points, terminal_aux = game_state.frame_step(a_t)\n",
    "            terminal = terminal_aux or terminal\n",
    "\n",
    "            r_t = points - prev_points if points >= prev_points else -100\n",
    "            prev_points = points\n",
    "\n",
    "            x_t1 = skimage.color.rgb2gray(x_t1_colored)\n",
    "            x_t1 = skimage.transform.resize(x_t1,(img_rows,img_cols), mode='constant')\n",
    "            #x_t1 = skimage.exposure.rescale_intensity(x_t1, out_range=(0, 255))\n",
    "\n",
    "            x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x80x80x1\n",
    "            s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3)\n",
    "\n",
    "            # store the transition in D\n",
    "            D.append((s_t, action_index, r_t, s_t1, terminal))\n",
    "            if len(D) > REPLAY_MEMORY:\n",
    "                D.popleft()\n",
    "\n",
    "            #only train if done observing\n",
    "            if t>0 and t % OBSERVE == 0:\n",
    "                #sample a minibatch to train on\n",
    "                minibatch = random.sample(D, BATCH)\n",
    "\n",
    "                inputs = np.zeros((BATCH, s_t.shape[1], s_t.shape[2], s_t.shape[3]))   #32, 80, 80, 4\n",
    "                #print (inputs.shape)\n",
    "                targets = np.zeros((inputs.shape[0], ACTIONS))                         #32, 2\n",
    "\n",
    "                #Now we do the experience replay\n",
    "                for i in range(0, len(minibatch)):\n",
    "                    state_t = minibatch[i][0]\n",
    "                    action_t = minibatch[i][1]   #This is action index\n",
    "                    reward_t = minibatch[i][2]\n",
    "                    state_t1 = minibatch[i][3]\n",
    "                    terminal = minibatch[i][4]\n",
    "                    # if terminated, only equals reward\n",
    "\n",
    "                    inputs[i:i + 1] = state_t    #I saved down s_t\n",
    "\n",
    "                    targets[i] = self.model.predict(state_t)  # Hitting each buttom probability\n",
    "                    Q_sa = self.model.predict(state_t1)\n",
    "\n",
    "                    if terminal:\n",
    "                        targets[i, action_t] = reward_t\n",
    "                    else:\n",
    "                        targets[i, action_t] = reward_t + GAMMA * np.max(Q_sa)\n",
    "                    \n",
    "                # targets2 = normalize(targets)\n",
    "                loss = self.model.train_on_batch(inputs, targets)\n",
    "\n",
    "                convout1_f = K.function(self.model.inputs, [self.convout1.output])\n",
    "                X = minibatch[0][3]\n",
    "                C1 = convout1_f([X])\n",
    "                C1 = np.squeeze(C1)\n",
    "\n",
    "                pl.figure(figsize=(15, 15))\n",
    "                pl.suptitle('convout1')\n",
    "                self.nice_imshow(pl.gca(), self.make_mosaic(C1, 8, 8), cmap=cm.binary)\n",
    "\n",
    "            s_t = s_t1\n",
    "            t = t + 1\n",
    "\n",
    "            # save progress every 1000 iterations\n",
    "            if t % 1000 == 0:\n",
    "                print(\"Now we save model\")\n",
    "                self.model.save_weights(\"model.h5\", overwrite=True)\n",
    "                with open(\"model.json\", \"w\") as outfile:\n",
    "                    json.dump(self.model.to_json(), outfile)\n",
    "\n",
    "            # print info\n",
    "            state = \"\"\n",
    "            if t <= OBSERVE:\n",
    "                state = \"observe\"\n",
    "            elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "                state = \"explore\"\n",
    "            else:\n",
    "                state = \"train\"\n",
    "\n",
    "            print(\"TIMESTEP\", t, \"/ STATE\", state, \\\n",
    "                    \"/ EPSILON %.5f \"% epsilon, \"/ ACTION\", action_index, \"/ R\", r_t, \\\n",
    "                    \"\\t/ Q_MAX %.5f \"% np.max(Q_sa), \"/ Loss %.5f\"% loss)\n",
    "            \n",
    "\n",
    "        print(\"Episode finished!\")\n",
    "        print(\"************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def playGame(args):\n",
    "    model = MyModel()\n",
    "    model.trainNetwork(args)\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Description of your program')\n",
    "    parser.add_argument('-m','--mode', help='Train / Run', required=True)\n",
    "    args = vars(parser.parse_args())\n",
    "    playGame(args)\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
